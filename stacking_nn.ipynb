{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5ade5-5fed-4281-afb7-5793cd15af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f91c99-5d05-4a15-8087-1a87ff076ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/processed/training_arm.pickle\", \"rb\") as f:\n",
    "    training_arm = pickle.load(f)\n",
    "\n",
    "with open(\"data/processed/output_models.pickle\", \"rb\") as f:\n",
    "    output_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667253ce-1137-46dd-8fac-255dfb55f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba9a73-6b99-4aff-9e6e-8cb03c661c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    output_models, training_arm,\n",
    "    test_size=0.3, random_state=2022\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "valid_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de45f0-0505-4e5d-9e67-50276391066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585ed29-3fbc-4c64-81ce-50e1e7283234",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNStacker(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, 10_000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10_000, 5_000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5_000, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "def trainer(model, criterion, optimizer, trainloader, validloader, epochs=20, verbose=True):\n",
    "    \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        losses = 0\n",
    "        for X, y in trainloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()       # Clear gradients w.r.t. parameters\n",
    "            y_hat = model(X.reshape(X.shape[0], -1))\n",
    "            loss = criterion(y_hat, y)  # Calculate loss\n",
    "            loss.backward()             # Getting gradients w.r.t. parameters\n",
    "            optimizer.step()            # Update parameters\n",
    "            losses += loss.item()       # Add loss for this batch to running total\n",
    "        train_loss.append(losses / len(trainloader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        valid_losses = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in validloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                valid_losses += loss.item()\n",
    "        valid_loss.append(valid_losses / len(validloader))\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch: {epoch + 1}, \"\n",
    "                  f\"Train loss: {losses / len(trainloader):.2f}, \"\n",
    "                  f\"Valid loss: {valid_losses / len(validloader):.2f}\")\n",
    "\n",
    "    results = {\"train_loss\": train_loss,\n",
    "               \"valid_loss\": valid_loss}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a695c-e8b8-463d-96ab-6f5f4b7501ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2022)\n",
    "\n",
    "model = NNStacker(input_size=6_001, output_size=3_000)\n",
    "model.to(device);\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "print(time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "trainer(model, criterion, optimizer, train_dataloader, valid_dataloader, verbose=True)\n",
    "print(time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780ebd1-2e04-40e1-8b46-c266562b8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(torch.Tensor(X_test).to(device))\n",
    "y_hat = y_hat.cpu().detach().numpy()\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_test - y_hat)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f331d7-76a0-47c0-9dd7-72db47cf8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_examples = 0\n",
    "bad_examples = 0\n",
    "\n",
    "ax_good = plt.subplot(121)\n",
    "ax_bad = plt.subplot(122)\n",
    "\n",
    "for X, y in valid_dataloader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    prediction = model(X)\n",
    "\n",
    "    y = y.cpu().detach().numpy()\n",
    "    prediction = prediction.cpu().detach().numpy()\n",
    "    \n",
    "    while good_examples < 30 and bad_examples < 30:\n",
    "        for i in range(X.shape[0]):\n",
    "            rmse = np.sqrt(np.mean((prediction[i, :] - y[i, :])**2))\n",
    "            if rmse < 5:\n",
    "                good_examples += 1\n",
    "                ax_good.plot(y[i, :1000], y[i, 1000:2000], color=\"r\")\n",
    "                ax_good.plot(prediction[i, :1000], prediction[i, 1000:2000], color=\"b\")\n",
    "            if rmse > 30:\n",
    "                bad_examples += 1\n",
    "                ax_bad.plot(y[i, :1000], y[i, 1000:2000], color=\"r\")\n",
    "                ax_bad.plot(prediction[i, :1000], prediction[i, 1000:2000], color=\"b\")\n",
    "\n",
    "ax_good.title.set_text(\"Good predictions\")\n",
    "ax_bad.title.set_text(\"Bad predictions\")\n",
    "ax_good.set_xlim([-150, 150])\n",
    "ax_good.set_ylim([-100, 100])\n",
    "ax_bad.set_xlim([-150, 150])\n",
    "ax_bad.set_ylim([-100, 100])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:monkey_dec]",
   "language": "python",
   "name": "conda-env-monkey_dec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
